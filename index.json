[{"categories":null,"content":"This is a test ","date":"01-01-0001","objectID":"/homepage/:0:0","tags":null,"title":"","uri":"/homepage/"},{"categories":["Theory"],"content":"CPU registers in 64-bit mode * rax * rbx * rbp * rsp first * rdi \u003c--+ * rsi | in 64-bit mode the first 6 parameters are placed in * rdx | these registers from rdi to r9 when calling a function, * rcx | any extra params are passed through the stack like in * r8 | 32-bit mode * r9 \u003c--+ last * r10-r15 ","date":"01-01-0001","objectID":"/64-bit-gcc_runtime_stack_usage/:1:0","tags":["C","Systems Programming","Assembly"],"title":"64-bit-GCC Runtime Stack Usage","uri":"/64-bit-gcc_runtime_stack_usage/"},{"categories":["Theory"],"content":"Simple C program in assembly #include \u003cstdio.h\u003e extern int B(); int A(int x, int y) { int d, e, f; d = 4; e = 5; f = 6; f = B(d,e); } cc -m32 -S \u003ccprog\u003e.c # compile into 32-bit assembly code .text .globl A ; ------------- Entry: -------------+ A: # A() start code location pushl %ebp movl %esp, %ebp # establishing the stack frame subl $24, %esp # allocate space for local vars etc ; ----------------------------------+ ; ------- Function body code: ------+ movl $4, -20(%ebp) # d = 4 movl $5, -16(%ebp) # e = 5 movl $6, -12(%ebp) # f = 6 subl $8, %esp # create 8 byte slot for tmp pushl -16(%ebp) # push e pushl -20(%ebp) # push d call B addl $16, %esp # clean stack movl %eax, -4(%ebp) # f = return value in AX register ; ----------------------------------+ ; ----------- Exit code: -----------+ leave ret ; ----------------------------------+ There are 3 parts to the assembly code: Entry: the stack frame is established, local variables and working space are allocated on the stack. First FP is saved on the stack (%ebp) Second point SP (%esp) to that saved FP, the stack looks like: --------------------- \u003e low address XXXX | PC | FP | ^ FP,SP --------------------- Then allocate 24 bytes of space for the local variables and working area by shifting SP (%esp) downward Function Body Code: assign the values to the variables and extra for tmp space. FP is used to locate the local variables, as they are all ints (sizeof(int) == 4) just do -4(FP), … descending in multiples of 4. The stack looks like: ---------------- -4 -8 -12 -16 -20 -24 ----- XXXX | PC | FP | ? | ? | 6 | 5 | 4 | ? | ^ f e d ^ FP SP --------------------------------------------- Then add the tmp space, using SP (%esp) as the guide before finally B is called, pushing the parameters onto the stack (in reverse order) ---------------- -4 -8 -12 -16 -20 -24 ------------------ XXXX | PC | FP | ? | ? | 6 | 5 | 4 | ? | ?? | ?? | e | d | ^ f e d TMP SPACE ^ FP SP ---------------------------------------------------------- Exit Code: returning the stack frame to the caller leave is the same as doing: ;leave movl %ebp, %esp popl %ebp ","date":"01-01-0001","objectID":"/64-bit-gcc_runtime_stack_usage/:2:0","tags":["C","Systems Programming","Assembly"],"title":"64-bit-GCC Runtime Stack Usage","uri":"/64-bit-gcc_runtime_stack_usage/"},{"categories":["Theory"],"content":"Function call convention /********* t.c file ********/ #include \u003cstdio.h\u003e int sub(int a, int b, int c, int d, int e, int f, int g, int h) { int u, v, w; u = 9; v = 10; w = 11; return a+g+u+v; // use first and extra parameter, locals } int main() { int a, b, c, d, e, f, g, h, i; a = 1; b = 2; c = 3; d = 4; e = 5; f = 6; g = 7; h = 8; i = sub(a,b,c,d,e,f,g,h); } First, to compile the c program and output the assembly code: gcc -S \u003ccprog\u003e.c # it will output a \u003ccprog\u003e.s file #------------ t.s file generated by 64-bit GCC compiler ------------– .globl sub sub: # int sub(int a,b,c,d,e,f,g,h) # first 6 parameters | a |,| b |,| c |,| d |,| e |,| f | # in registers: |rdi|,|rsi|,|rdx|,|rcx|,|r8d|,|r9d| # 2 extra parameters g,h are on stack. # Upon entry, stack top contains g, h # ------------------------------------- # . . . ...| h | g | PC | LOW address ^ # RSP # ------------------------------------ # establish stack frame pushq %rbp movq %rsp, %rbp # no need to shift rsp down because each function has a 128 bytes # reserved stack area. # rsp will be shifted down if function define more locals # save first 6 parameters in registers on stack movl %edi, -20(%rbp) # a movl %esi, -24(%rbp) # b movl %edx, -28(%rbp) # C movl %ecx, -32(%rbp) # d movl %r8d, -36(%rbp) # e movl %r9d, -40(%rbp) # f # access locals u, v, w at rbp -4 to -12 movl $9, -4(%rbp) movl $10, -8(%rbp) movl $11, -12(%rbp) # compute x + g + u + v: movl -20(%rbp), %edx # saved a on stack movl 16(%rbp), %eax # g at 16(rbp) addl %eax, %edx movl -4(%rbp), %eax # u at -4(rbp) addl %eax, %edx movl -8(%rbp), %eax # v at -8(rbp) addl %edx, %eax # did not shift rsp down, so just popQ to restore rbp popq %rbp ret # ====== main function code in assembly ====== .globl main main: # establish stack frame pushq %rbp movq %rsp, %rbp # shift rsp down 48 bytes for locals subq $48, %rsp # locals are at rbp -4 to -32 movl $1, -4(%rbp) # a=1 movl $2, -8(%rbp) # b=2 movl $3, -12(%rbp) # c=3 movl $4, -16(%rbp) # d=4 movl $5, -20(%rbp) # e=5 movl $6, -24(%rbp) # f=6 movl $7, -28(%rbp) # g=7 movl $8, -32(%rbp) # h=8 # call sub(a,b,c,d,e,f,g,h): first 6 parameters in registers movl -24(%rbp), %r9d # f in r9 movl -20(%rbp), %r8d # e in r8 movl -16(%rbp), %ecx # d in ecx movl -12(%rbp), %edx # c in edx movl -8(%rbp), %esi # b in esi movl -4(%rbp), %eax # a in eax but will be in edi # push 2 extra parameters h,g on stack movl -32(%rbp), %edi # int h in edi pushq %rdi # pushQ rdi ; only low 32-bits = h movl -28(%rbp), %edi # int g in edi pushq %rdi # pushQ rdi ; low 32-bits = g movl %eax, %edi # parameter a in edi call sub # call sub(a,b,c,d,e,f,g,h) addq $16, %rsp # pop stack: h,g, 16 bytes movl %eax, -36(%rbp) # i = sub return value in eax movl $0, %eax # return 0 to crt0.o leave ret ","date":"01-01-0001","objectID":"/64-bit-gcc_runtime_stack_usage/:3:0","tags":["C","Systems Programming","Assembly"],"title":"64-bit-GCC Runtime Stack Usage","uri":"/64-bit-gcc_runtime_stack_usage/"},{"categories":["Theory"],"content":"Each CPU has the following registers (64-bit in parantheses): PC (IP): Instruction pointer - Points to next instruction for the CPU to execute SP (SP): Stack pointer - Points to the top of the stack FP (BP): Base pointer - Points to the stack frame of the current active function RVR (AX): Return value - Points to the function return value main() | int sub(int x, int y) { | { int a, b, c; | int u, v; a = 1; b = 2; c = 3; | u = 4; v = 5; c = sub(a, b); | return x+y+u+v; printf(\"c=%d\\n\", c); | } } | When a C program is envoked, the return address (current PC) is pushed onto the stack and then the value stored in the PC register is replaced with the function we wish the CPU to execute. In the above case when we wish to run the program (call main()), the current PC is pushed and PC is replaced by the entry address of main(). In this diagram XXXX denotes stack data before we run the program: (Stack grows downward) High address --\u003e Low address ------------------------------------- | XXXX | PC | ^ SP ------------------------------------- Every C program follows the same procedure when called (following main and sub program): Push FP onto the stack to save the CPU’s previous stack frame location | XXXX | PC | FP | ^ SP Point FP to the new FP to establish the new stack frame | XXXX | PC | FP | ^ SP,FP Allocate space for auto local variables, but don’t initialise them a b c | XXXX | PC | FP | ? | ? | ? | ^ ^ FP SP Potentially allocate more for temporary memory (denoted by tmp) a b c | XXXX | PC | FP | ? | ? | ? | tmp | ^ ^ FP SP The code starts executing, in our case assigning the values to the variables (in main) comes first a b c | XXXX | PC | FP | 1 | 2 | 3 | tmp | ^ ^ FP SP Using the assumption that we know an int is 4 bytes (i.e sizeof(int) == 4), the assignments can be done individually by simply measuring the distance between the FP we saved and the registers next to it, thus -4(FP) == a, -8(FP) == b and -12(FP) == c. In assembly code this would look like: movl $1, -4(%ebp) /* move value 1 ($1) into register located -4(FP)*/ movl $2, -8(%ebp) movl $3, -12(%ebp) In our case, main() calls sub() via a direct assignment to the variable c. First the parameters given to the sub() method are pushed in reverse order, so b and then a. We then repeat the same steps (because this is a C program) from 1. to make the CPU execute the sub() function. So it would look something like this afterwards: Stack frame of Stack frame of |---------- main() ----------| |--------- sub() ---------| a b c b a u v | XXXX | PC | FP | 1 | 2 | 3 | tmp | 2 | 1 | PC | FP | 4 | 5 | tmp | ^ ^ ^ | FP SP +------------ points to ------------+ You can also see from this diagram that accessing the parameters given to a function is positively relative to the FP rather than negative: 8(FP) == a and 12(FP) == b. This format is exactly how a stack looks to the calling function, or more generally: | -------------------- Function's stack frame ----------------------| | params | return PC (CPU should return to) | saved FP | local vars | A simple program like this: crt0.o -\u003e main() -\u003e A(par_a) -\u003e B(par_b) -\u003e C(par_c) Should look like this when thinking of stack frames: SF of SF of ... |- main() -| |- A() -| ... | 0 | ^ +--| FP0 | ^ +--| FPmain() | ^ +--| FPA() | ^ +--| FPB() | ^ +--| FPC() | ^ CPU.FP The return value of sub() is placed into the AX register and the function returns to the callers stack frame. Before returning however, the local variables must be deallocated: First copy the value of the current FP into SP, so they are pointing to the same thing a b c b a | XXXX | PC | FP | 1 | 2 | 3 | tmp | 2 | 1 | PC | FP | ^ FP,SP Next pop the stack into the FP pointer, giving it the FP of the caller a b c b a | XXXX | PC | FP | 1 | 2 | 3 | tmp | 2 | 1 | PC | ^ ^ FP SP,(CPU.PC) Finally the RET function is executed, popping the top of the stack into the PC register, making the CPU execute from the saved return address, belonging to the caller a b c b a | XXXX | PC | FP | 1 | 2 | 3","date":"01-01-0001","objectID":"/c_function_calls/:0:0","tags":["C","Systems Programming","Assembly"],"title":"C function calls (32-bit)","uri":"/c_function_calls/"},{"categories":["Theory"],"content":"Side note: long jump A long jump can be used to esentially skip returning to the caller, and return elsewhere, normally earlier than the caller. If we have a program in which: main() -\u003e A() -\u003e B(), but upon return B() jumps to main() instead of its caller A(). /** longjump.c file: demonstrate long jump in Linux **/ #include \u003cstdio.h\u003e #include \u003csetjmp.h\u003e jmp_buf env; // for saving longjmp environment int main() { int r, a=100; printf(\"call setjmp to save environment\\n\"); if ((r=setjmp(env)) == 0){ // saves cur exec env in jmp_buf strct A(); printf(\"normal return\\n\"); } else printf(\"back to main() via long jump, r=%d a=%d\\n\", r, a); } int A() { printf(\"enter A()\\n\"); B(); printf(\"exit A()\\n\"); } int B() { printf(\"enter B()\\n\"); printf(\"long jump? (y|n) \"); if (getchar()=='y') longjmp(env, 1234); printf(\"exit B()\\n\"); } The idea is that the registers containing the callers PC and FP are replaced by the values stored in the jmp_buf struct, which in the above example are main()’s, which means we can follow the regular steps and we will skip A() completely. It is also possible for the longjmp() function to save the CPU’s current registers and SP so that it can be restored if needed. Replace with saved | | XXXX | PC | FP | ... | =\u003e | XXXX | SavedPC | SavedFP | ... | ^ ^ ^ ^ FP SP FP SP ","date":"01-01-0001","objectID":"/c_function_calls/:0:1","tags":["C","Systems Programming","Assembly"],"title":"C function calls (32-bit)","uri":"/c_function_calls/"},{"categories":["Theory"],"content":"FUSE (filesystem in user space) [1] ","date":"01-01-0001","objectID":"/fuse/:0:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"What is FUSE, and why use it? FUSE is an open source framework which allows you to build filesystems in user space, compared to the conventional kernel space route. Building in user space is said by many to not be suitable for production, and also that the overhead is too substantial to be of use. But this allows the programmer to work in a ‘friendlier’ environment, gives a much larger toolset to work with and probably most importantly, it doesn’t crash the system on a bug like kernel programming does. It is important to note that if Unix FS were created in user space then they would be readily accessed under Windows. ","date":"01-01-0001","objectID":"/fuse/:1:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"FUSE architecture: how does it work? FUSE has a kernel part and a userland part. The kernel module (fuse.ko) and a fuse daemon, they communicate via a character device /dev/fuse. Upon initiation the fuse kernel module registers 3 filesystem types within the VFS: fuse, fuseblk and fusectl. The fuse type is for stackable (i.e on top of an already existing, kernel FS)/in-memory/network filesystems. fuseblk is for block devices containing user space file systems. fuse and fuseblk will be what is referred in this post as FUSE. Finally fusectl allows users to control and monitor FUSE FS behaviour. Due to the FUSE filetype being able to represent many different FSs, unlike kernel-level FSs (e.g Ext4), they have a name attached to them when listed by Linux. Side note: VFS [2] The VFS (virtual file system) in Linux is used to give a level of abstraction to user-space applications about all the mounted filesystems, which allows for a unified look and feel. It does this by abstracting out the common filesystem code from each mounted filesystem to make a seperate layer, which in turn calls the underlying filesystem to manage its own data. All POSTIX system calls (related to files/directories) must go through VFS first before reaching any underlying filesystem, this is the “high-level interface”. The “low-level interface” is the communication between the VFS and file system itself, called the VFS interface. Filesystem developers must supply the VFS with all the required VFS interface methods for that filesystem (read/write/readdir/etc). It is because of this interface that allows for all different filesystem types to coexist due to the VFS not needing to know where the file is located, only where to find the filesystem operations to work on the file. When a filesystem registers with the VFS, it is simply providing that list of addresses containing the methods required. For example, a filesystem has just been mounted at /mnt and the user is requesting a read operation on one file (read(\"/mnt/foo/file.txt\")): The VFS first searches for the FS (filesystem) requested in the /mnt directory It then finds that FS’ superblock and its root directory (/mnt/) from within the superblock The VFS can then find the foo/file.txt file path It then creates a v-node and makes a call to the containing FS to collect the information from file.txt’s inode This is then copied to the v-node (in RAM) along with other info which includes the pointer to the table of function calls to be used on v-nodes from the underlying FS Once the v-node is created the VFS adds an entry into the file descriptor table for the calling process and sets it to point to the new v-node, which is returned to the calling process, allowing it to now make read/write/close calls on the file Later when the caller makes a read call on the file using the fd, the VFS locates the corresponding v-node from the processes file descriptor table, follows the pointer to the table containing all of the methods of the underlying FS containing that file (which themselves are addresses located in the FS itself) The image above shows a high level overview of the basic communication between FUSE and the VFS. In more detail, if a user-level application accesses the FUSE FS: ","date":"01-01-0001","objectID":"/fuse/:2:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"APIs: Low-level vs High-level FUSE offers developers two different API levels to choose from: a high-level and a low-level. A high-level filesystem implementation would see a simpler codebase but generally worse performance compared to its counterpart. The low-level API is the only one of the two which communicates directly with the kernel, meaning it has 4 key differences: It receives and parses kernel requests It sends properly formatted replies to the kernel It facilitates filsystem config and mounting Finally it hides version differences between the user and kernel spaces This means that the high-level API builds on top of the low-level, and all requests/replies must be passed through it if the high-level wishes to communicate with the kernel. One reason the complexity is reduced in the high-level is the fact that developers are not forced to do path-to-inode mapping, rather they are given the pathname directly. This is shown here: Side note: inodes [3] In modern Linux systems, every file has an associated inode. This datastructure contains the following information: The file’s metadata 12 Indirect pointers, where each pointer ‘points to’ a data block of the file, in order 1 Indirect pointer, which points to the head of another list of 12 indirect pointers, should the first 12 not be enough to cover the size of the file 2 Indirect pointers, the same logic as above, but containing 2 3 Indirect pointers, again but containing 3 Below is an example using file.txt’s inode: inode structure --------------- inode file.txt | metadata | | 12 ind. | ptr(0) --\u003e | datablock | | | ... | ptrs | ptr(11) --\u003e | datablock | | ind. ptr | --\u003e | 12 ind. | ptr(0) --\u003e | datablock | | | ... | ptrs | ptr(11) --\u003e | datablock | | 2 x ind. | --\u003e | ind. ptr | --\u003e | 12 ind. | ptr(0) --\u003e | datablock | | | ... | ptrs | ptr(11) --\u003e | datablock | | ptrs | --\u003e | ind. ptr | --\u003e | 12 ind. | ptr(0) --\u003e | datablock | | | ... | ptrs | ptr(11) --\u003e | datablock | |3 x ind. ptr| ... Following the Unix philosophy that ’everything is a file’, directories also have inodes, but instead of mapping the first ind. ptr to a file’s datablock, they map a filename to its inode: inode structure --------------- directory inode | metadata | | 12 ind. | ptr(0) --\u003e | file1.txt's inode | | | ... | ptrs | ptr(11) --\u003e | file12.txt's inode | | ind. ptr | --\u003e | 12 ind. | ptr(0) --\u003e | file13.txt's inode | | | ... | ptrs | ptr(11) --\u003e | file24.txt's inode | | 2 x ind. | ... | ptrs | ... |3 x ind. ptr| ... So to get the data of a file ‘/foo/file.txt’ from ‘/’: \"/\" \"/foo\" \"/foo/file.txt\" | \"/\"s inode | ... | ind. ptr | --\u003e | \"foo\"s inode | ... ... | ind. ptr | --\u003e | \"file.txt\"s inode | ... ... | ind. ptr | --\u003e | data block | ... The main differences then, between low and high-level: Low-level methods all take a fuse request as an argument, high-level methods do not Lookup and forget methods are used by the high-level when the kernel removes an inode from either the inode or dentry cache. Due to the high-level not using inodes, the low-level handles this instead When a request comes in from the kernel, the low-level lib takes it and either searches in the low_level_ops struct or the high_level_ops struct depending on which api the developer used and runs the code found inside. The high-level will pass the response down to the low-level which will handle it there before passing the response to the kernel, hence one of the main reasons of the performance difference of the two apis. ","date":"01-01-0001","objectID":"/fuse/:3:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"Per connection session information The user-kernel protocol (mentioned previously) offers a mechanism to store opened file’s/dir’s information. In the low-level lib, each method gets a fuse_file_info struct which is used to hold such information. It contains a filehandle which can point to the file/dir. Taking advantage of this capability allows the protocol to be stateful. Developers are also allowed to leave it stateless (by not using the struct), but this leads to the daemon constantly needing to open/close the files and directories manually upon each operation, leading to potential performance degredation. ","date":"01-01-0001","objectID":"/fuse/:4:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"Queues The fuse kernel holds 5 different queues, with each queue providing a specific purpose: Interrupts (highest priority) - For all interrupt requests Forgets - For all forget requests Pending - Latency sensitive requests (related to metadata) Background - All other requests (read/write etc) Processing - The requests that are currently being processed by the daemon It is important to note that one request can only belong to one queue at a time. For performance reasons forget requests must be throttled as many can come at once and take over the queue, hence why there is a seperate forget queue. For every 8 non-forget request there are 16 forgets. The oldest requests in the pending queue are ’taken’ by the user space daemon, and when this happens the kernel updates the queues to match, by removing the request from the pending queue into the processing queue. When the user-space daemon replies to the kernel that a process is finished (via the /dev/fuse character device), the kernel removes this request from the processing queue. This queue doesn’t have a tail due to the daemon replying with confirmation of arbitrary requests, thus there is no order there. Another important note is that interupt and forget requests do not get a reply, thus those requests are removed completely when taken. ","date":"01-01-0001","objectID":"/fuse/:5:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"Splicing and FUSE buffers Every read/write call to /dev/fuse requires a memory copy of the data between the kernel and user-space. Write requests and read replies can be the most harmful due to the potential size of the data that needs to be processed. FUSE uses splicing (offered by the linux kernel) which allows the user-space to transfer data between 2 in-kernel memory buffers without the need to copy the data to user space. In the low-level api, the write_buf method can be used to splice data from /dev/fuse into a linux pipe. It then passes the data as a buffer containing the pipes fd. For this to happen there must be more than a single page of data. It is important to note that for reads in the low-level api, developers must differentiate between splice and non-splice flows inside the read method itself. ","date":"01-01-0001","objectID":"/fuse/:6:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Theory"],"content":"References [1] : Vangoor, Bharath Kumar Reddy, Vasily Tarasov, and Erez Zadok. “To {FUSE} or Not to {FUSE}: Performance of User-Space File Systems.” In 15th {USENIX} Conference on File and Storage Technologies ({FAST} 17), pp. 59-72. 2017. [2] : Tanenbaum, A. S., and H. Bos. “Modern Operation Systems 4th Edition.” (2014). [3] : Inode structure, Udacity, 2015, https://www.youtube.com/watch?v=tMVj22EWg6A ","date":"01-01-0001","objectID":"/fuse/:7:0","tags":["Systems Programming","FUSE","File Systems"],"title":"FUSE","uri":"/fuse/"},{"categories":["Tutorial"],"content":"Create a new site in a directory \u003csite_name\u003e hugo new site \u003csite_name\u003e ","date":"01-01-0001","objectID":"/hugo-basics/:1:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Running the server locally (-D flag is to render pages marked as drafts) hugo server -D ","date":"01-01-0001","objectID":"/hugo-basics/:2:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Github This repo has the alternate stream set to ‘development’. So pushing master to here will not effect the site itself. ","date":"01-01-0001","objectID":"/hugo-basics/:3:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Deploying ./deploy.sh This script deploys the website to the repo georgesims21.github.io as a proper site. It will not render files marked as drafts, so it should look exactly the same as locally if you run: hugo server ","date":"01-01-0001","objectID":"/hugo-basics/:4:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Structure ","date":"01-01-0001","objectID":"/hugo-basics/:5:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Archetypes/ An ‘archetype’ is something common across the whole website. Can be metadata, or data about data found in here. The default.md file contains the frontmatter defaults for each newly created page. You can create \u003cdirectory_name\u003e.md to make specific directory archetypes. ","date":"01-01-0001","objectID":"/hugo-basics/:6:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Content Contains all of your pages (content of the website) ","date":"01-01-0001","objectID":"/hugo-basics/:7:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Organisation Within content/ you can create singular pages and directories containing pages for better organization. structure/dir1/pageA.md would have a URL: localhost:1313 or \u003cgithub.io\u003e/dir1/pageA The homepage will contain all single page content in the folders. If you go to \u003c\u003e/dir1, you will then only see files within the dir1 directory. This only goes 1 level deep, so \u003c\u003e/dir1 will show files but \u003c\u003e/dir1/dir2 wouldn’t show a list page for dir2, you must create it manually by adding an index file to dir2. ","date":"01-01-0001","objectID":"/hugo-basics/:7:1","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Index pages hugo new content/dir1/dir2/_index.md Index pages are used to put information on the list pages (directories). If a dir doesn’t have one then you cannot write custom content. They must be named ‘_index.md’ to work, but they can have different titles within the index metadata. ","date":"01-01-0001","objectID":"/hugo-basics/:7:2","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Frontmatter/metadata Located at the top of each page/index and contains key:value pairs. Can be written in YAML(default), TOML and JSON. Most of this data will be displayed on list pages, i.e if you have a title : “A” and date : “12th Apr” on a content file, then the blog post will have this info when on the coresponding list page. You can define custom frontmatter variables to use on each page. Taxonomies Ways to logically group content on site, tags and categories. Defined by: tags: [\"tag1\", \"tag2\", ...] categories: [\"cat1\", \"cat2\", ...] HUGO automatically creates list pages in tags/ and links tags together. If you want to define a custom taxonomy properly, you can define it in the same way as tags/categories but inside the config.toml file you must add it. \u003cdefault inside file\u003e ... [taxonomies] tag = \"tag\" category = \"categories\" mood = \"moods\" By default tags/cats work out of the box, but whenever you want to define a custom one you must add them manually like above plus the new one. A server restart is needed for the changes to take effect. ","date":"01-01-0001","objectID":"/hugo-basics/:7:3","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Data Acts like a database in a way. Can have data files you wish to pull info from on your site ","date":"01-01-0001","objectID":"/hugo-basics/:8:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Layouts Things like: I want to have the same header and footer on each page. This can be defined within files in here ","date":"01-01-0001","objectID":"/hugo-basics/:9:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Static Storing all the static elements of the website. Things that don’t change (image, css file etc) ","date":"01-01-0001","objectID":"/hugo-basics/:10:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Themes Contains a downloaded theme. Should run git submodule add \u003ctheme_repo\u003e themes/\u003cname\u003e ","date":"01-01-0001","objectID":"/hugo-basics/:11:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Tutorial"],"content":"Shortcodes (auto-html/templates) To avoid working with html to add things like embedded videos from YT or similar, shortcodes can be used to do this automatically. {{/\u003c \u003cshortcode_name\u003e \u003cparam1\u003e \u003cparam2\u003e ... /\u003e}} # Generic {{/\u003c youtube \u003cvideo_id\u003e /\u003e}} # To embed YT vid ","date":"01-01-0001","objectID":"/hugo-basics/:12:0","tags":["Hugo","Basics"],"title":"Hugo basics","uri":"/hugo-basics/"},{"categories":["Theory"],"content":"TCP (Transmission Control Protocol)/IP (Internet Protocol) is the backbone of the internet. There are 2 versions: IPv4 (32-bit addresses) and IPv6 (64-bit). The figure below shows the TCP/IP layers: The top layer shows applications which use networking to transfer/collect data. They either use TCP or UDP (mentioned later). Data transfer at this level is only logical, the real transferring takes place at the bottom two layers (Internet and Link layers). This is where the data packets are divided into data frames for transmission over physical networks. This is represented in the data flow diagram below: Every host (device supporting the TCP/IP protocol) is identified by a 32-bit address called an IP address. These are represented in a dot notation where the individual bytes are separated by dots. A hostname (i.e www.) and IP are the same, only the DNS (Domain Name System) translate between the two for simplicity. There are two parts to an IP address: NetworkID field and HostID field, where the leading two bits are the NetworkID and the rest the HostID. Data intended for an IP address are sent to a router with the same NetworkID, this router will then forward the packets to a specific host on the network with the same HostID. Every host has a localhost name (default IP: 127.0.0.1). IP protocol is used for sending/receiving data packets between IP hosts, operating in a best effort manner. This means there is no guarantee that packets will arrive at their destinations or arrive in order, thus IP is not a reliable protocol. Reliability, if needed, must then be implemented above the IP layer. An IP packet consists of an IP header, sender and receiver IP addreses, an IP header looks like this: It is usually not possible to send data packets directly from one host to another due to the distance between them. Routers are special IP hosts which receive and forward these packets, so if one receives a packet not meant for them, it will pass it on to the next router, which is called a hop. If however the packet does not arrive at its intended destination it doesn’t simply stay hopping around on the network. All packets have a Time-To-Live (TTL) count in the header, its job it to reduce by one upon each hop, and when it hits 0 that router will drop the packet. This number can be max 255 (8-bit). The UDP (User Datgram Protocol) like IP, doesn’t guarantee reliability, but is fast and efficient. This protocol is used by applications where reliability isn’t essential (e.g ping). The TCP (Transmission Control Protocol) does guarantee reliable data transfers, but is much less efficient. Each host may have multiple TCP/UDP connections happening at once, thus they all must be uniquely identified by a triple: Application = (HostIP, Protocol, PortNumber) Where PortNumber is a unique unsigned short integer. In TCP applications the first 1024 ports are reserved: The dataflow in TCP/IP networks looks like this: Where each layer adds some form of data as a header, and shows the direction these packets go through each one. The receiving host translates the data going in the opposite direction to this chart. ","date":"01-01-0001","objectID":"/networking_basics/:0:0","tags":["C","Systems Programming","Networking"],"title":"Networking basics","uri":"/networking_basics/"},{"categories":["Theory"],"content":"procfs and sysfs are both pseudo filesystems located in the root directory of the Unix FS heirarchy. They contain files which act as a window to the kernel and allows user-land processes to see and change important system information. Upon inspection (if you wrote the command $ ls -al /proc on a Unix system) you would notice that all files are 0 in size. This is due to the window aspect, one a user-land process reads/opens one of these files, it is at that moment the kernel writes that information to the file, hence the analogy. Imagine you are out shopping, where the shops changed their items every second, and only when you look through the window will the shop owner place their items in view for you to see, saving the shop owner a lot of energy if you only decide to look once every minute. There are files containing singular process information as well as system wide information, and procfs uses symlinks to allow processes to automatically see stats releated to the caller, without the caller making extra effort. sysfs contains files which interact with the kernel and allows user-land processes to modify kernel parameters without entering the kernel themselves. Processes can write to these files and the kernel will update the parameters accordingly within the kernel. The aim of my bachelor project is to create a filesystem using FUSE which mirrors procfs and sysfs for a distributed setting. To begin planning, it is important to realise which filesystem operations I will actually need to implement, and which ones I should leave out. After checking the linux/fs/proc/generic file (which contains the main filesystem operations for procfs on the master branch) I found that these were the ones given to the VFS by procfs: getattrb readdir llseek read lookup setattrb create symlink mkdir open release remove Apart from llseek and the remove operation, all of these methods are offered by the FUSE api to be used within a new FS. Due to my bachelor project mirroring procfs, operations which modify files/directories in any way should not be implemented, thus here are the final operations which I must implement: getattrb readdir read lookup open test ","date":"01-01-0001","objectID":"/procfs/:0:0","tags":["Systems Programming","FUSE","File Systems","procfs"],"title":"procfs/sysfs","uri":"/procfs/"},{"categories":["Tutorial"],"content":"This tutorial assumes you know the basic concepts of multithreading. It is based on this short video series by Dr. Brian Fraser ","date":"01-01-0001","objectID":"/pthreads/:0:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Creating single threads The pthread library (POSTIX thread) allows C programmers to use multithreading capabilities. First you must define the \u003cpthread.h\u003e header, and link -pthread when compiling the program. The function to create a thread is the pthread_create(): \u003cpthread.h\u003e int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); This takes 4 different parameters: The pthread_t thread variable you wish to use Any special attributes you wish this thread to have contained in the pthread_attr_t struct The routine you want this thread to do. This will be a function pointer, and this pointer should return a void* as well as accepting void* as params. Finally any arguments you wish to pass to this routine From this it is important to point out that threads can only run routines which return and take void pointer types. This means casting must be done within the routine if you wish to use particular variables. #include \u003cstdio.h\u003e #include \u003cpthread.h\u003e /* * Simply allow a thread to increment a global variable */ int limit = 0; // global as threads share address space void* run(void* arg) { int *lim = (int *)arg; // must cast the void pointer // int lim = *(int *)arg; would dereference and place value in lim instead printf(\"Thread running, before incrementing limit is: %d\\n\", limit); *lim = *lim + 1; printf(\"Thread running, after incrementing limit is: %d\\n\", limit); pthread_exit(0); } int main(void) { printf(\"In main before thread, limit is: %d\\n\", limit); // create thread pthread_t tid; // create attributes - can also pass NULL if not needed pthread_attr_t attr; // init attributes pthread_attr_init(\u0026attr); // create and run thread pthread_create(\u0026tid, \u0026attr, run, \u0026limit); // run is function pointer as without // paranthesis it points to starting // address of function // wait for thread to finish pthread_join(tid, NULL); // if param 2 is NULL, main ignores any return value printf(\"In main after thread, limit is: %d\\n\", limit); return 0; } The output of such program should look like this: ➜ ~ gcc -Wall threads.c -lpthread -o threads ➜ ~ ./threads In main before thread, limit is: 0 Thread running, before incrementing limit is: 0 # Thread is running Thread running, after incrementing limit is: 1 # while main waits In main after thread, limit is: 1 It is important to note that without the pthread_join function in this program, the main thread would simply print the statement and return without giving the thread a chance. ","date":"01-01-0001","objectID":"/pthreads/:1:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Returning a value from the run function In the previous example a global variable was used. If you want to return a variable from the function you must use pthread_exit() and catch it when using pthread_join like so: void* run(void* arg) { int value; ... pthread_exit(\u0026value); // auto-converted to void* by method } int main(void) { ... int *retval; pthread_join(tid, (void **)\u0026retval); // join returns ptr to ptr of type void ... } ","date":"01-01-0001","objectID":"/pthreads/:2:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Giving multiple parameters to the run function The problem with having the void* as a parameter for the run function is giving more than one argument. The only way to pass more than one would be to create a struct containing all of the variables that you wish to pass to the function. It is good practice to name this similar to the function itself: ... struct run_struct { // name matching function int limit; int answer; }; void* run(void* arg) { struct run_struct *args = (struct run_struct *) arg; // typecast to use vars args-\u003eanswer = args-\u003elimit++; ... } int main(void) { ... struct run_struct rs = {5, 0}; ... pthread_create(\u0026tid, \u0026attr, run, \u0026rs); // here the struct is given as param ... printf(\"In main after thread, answer is: %d\\n\", rs.answer); } ","date":"01-01-0001","objectID":"/pthreads/:3:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Creating multiple threads Multiple threads can be created using a for loop: ... pthread_t tids[10]; // create array of threads size 10 for(int i = 0; i \u003c= 10; i++) { // this can be done here for each or you can use one pthread_attr_t for // all threads, if you wish them to have the same attributes pthread_attr_t attr; pthread_attr_init(\u0026attr); pthread_create(\u0026tids[i], \u0026attr, run, \u0026limit); // create 10 threads } for(int i = 0; i \u003c= 10; i++) { pthread_join(tids[i], NULL); // make main wait for all of them } ... ","date":"01-01-0001","objectID":"/pthreads/:4:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Multiple threads having own param variables #include \u003cstdio.h\u003e #include \u003cpthread.h\u003e /* * Allow multiple threads to increment their own struct variable and save into the other * then main waits and prints. - Doesn't increment but too lazy to change */ struct run_struct { int limit; int answer; int tn; }; void* run(void* arg) { struct run_struct *args = (struct run_struct *) arg; printf(\"Thread[%d] running, before incrementing answer is: %d\\n\", args-\u003etn, args-\u003eanswer); args-\u003eanswer = args-\u003elimit++; printf(\"Thread[%d] running, after incrementing answer is: %d\\n\", args-\u003etn, args-\u003eanswer); pthread_exit(0); } int main(void) { struct run_struct rs[10]; // to give all threads own variables for function for(int i = 0; i \u003c 10; i++) { rs[i].limit = 5; rs[i].answer = 0; rs[i].tn = 0; } // create threads pthread_t tids[10]; pthread_attr_t attr; pthread_attr_init(\u0026attr); // create and run threads with threads own param struct for(int i = 0; i \u003c 10; i++) { rs[i].tn = i; // give thread it's own tid pthread_create(\u0026tids[i], \u0026attr, run, \u0026rs[i]); // each thread gives own // struct as param pointer } // wait for thread to finish for(int i = 0; i \u003c 10; i++) { pthread_join(tids[i], NULL); // if param 2 is NULL, main ignores any return value printf(\"In main after thread[%d], limit is: %d\\n\", i, rs[i].answer); } return 0; } If you compile and run the above program, you will see that the order of execution is only kept when main is printing the variables due to the wait function, but the threads themselves can finish before the others without order.. but main won’t print information for a thread if the one before hasn’t finished. Example output: ➜ ~ gcc -Wall threads.c -lpthread -o threads ➜ ~ ./threads Thread[0] running, before incrementing answer is: 0 Thread[0] running, after incrementing answer is: 5 Thread[1] running, before incrementing answer is: 0 Thread[4] running, before incrementing answer is: 0 # not in order Thread[6] running, before incrementing answer is: 0 Thread[6] running, after incrementing answer is: 5 Thread[2] running, before incrementing answer is: 0 Thread[5] running, before incrementing answer is: 0 Thread[5] running, after incrementing answer is: 5 In main after thread[0], limit is: 5 # Thread[0] has finished so main can print it Thread[4] running, after incrementing answer is: 5 Thread[8] running, before incrementing answer is: 0 Thread[8] running, after incrementing answer is: 5 Thread[2] running, after incrementing answer is: 5 Thread[3] running, before incrementing answer is: 0 Thread[3] running, after incrementing answer is: 5 Thread[1] running, after incrementing answer is: 5 Thread[9] running, before incrementing answer is: 0 Thread[9] running, after incrementing answer is: 5 In main after thread[1], limit is: 5 In main after thread[2], limit is: 5 In main after thread[3], limit is: 5 In main after thread[4], limit is: 5 In main after thread[5], limit is: 5 In main after thread[6], limit is: 5 # 8 will not be printed until 7 is finished Thread[7] running, before incrementing answer is: 0 Thread[7] running, after incrementing answer is: 5 In main after thread[7], limit is: 5 # now 7 is done 8 can proceed In main after thread[8], limit is: 5 In main after thread[9], limit is: 5 ","date":"01-01-0001","objectID":"/pthreads/:5:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Thread syncronization ","date":"01-01-0001","objectID":"/pthreads/:6:0","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Tutorial"],"content":"Mutexes When threads modify the same address or variable, there is no telling which will go first and most likely without any form of syncronisation you will get race conditions.It is important to correctly identify the critical section(s) within the code and add some form of syncronisation to that area, so only one thread at a time can access this area. A mutex (or mutual exclusion) allows for such a scenario. pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; // macro used for init of mutex ... // critical section start pthread_mutex_lock(\u0026mutex); ... // only 1 thread can acess this area of code pthread_mutex_unlock(\u0026mutex); // critical section end Keep in mind however that mutexes should only be used when needed as they make expensive calls to the kernel. Further reading: Implementing thread pools in C ","date":"01-01-0001","objectID":"/pthreads/:6:1","tags":["C","Multithreading"],"title":"pthreads in C","uri":"/pthreads/"},{"categories":["Theory"],"content":"The C socket API allows a developer to design and build a TCP/IP client/server program. To begin with a socket address structure is needed (\u003csys/socket.h\u003e): struct sockaddr_in { sa_family_t sin_family; // AF_INET for TCP/IP in_port_t sin_port; // port number struct in_addr sin_addr; // IP address }; struct in_addr { // internet address (in_addr) uint32_t s_addr; // IP address in network byte order }; for TCP/IP connections sin_family is always set to AF_INET, sin_port contains the port number (in network byte order) and finally sin_addr is the host IP address, also in network byte order. In this socket API, the server must create a socket and bind it with a sockaddr, which is the server’s IP address and port number. A fixed port number can be used or left as 0 to allow the OS kernel to choose it. A client must also create a socket if it wishes to communicate/connect with this server. This client may bind its socket to a server address, if it doesn’t then it must use that server’s socket address in all subsequent sendto() and recvfrom() calls. int socket(int domain, int type, int protocol); // definition in socket.h int tcp_sock = socket(AF_INET, SOCK_STREAM, 0); // creates a TCP socket for send/recv This socket must be bound with a host address and port number once created via the bind system call: int bind(int sockfd, struct sockaddr *addr, socklen_t addrlen) For TCP connections it must be bound to the server host address first. addrlen is the size in bytes of the address structure pointed to by addr. Once this connection is established a TCP server must use listen() and accept() to accept connections from client machines: int listen(int sockfd, int backlog); // allows for incoming connections on sockfd, backlog is the max queue size for pending connections int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); // accept a socket int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); // connect that socket The accept syscall takes the first socket in the pending queue and creates a new connected socket, returning the file descriptor to said socket. When accepting a new socket, the TCP server blocks until the connection is made via the connect syscall. This call connects sockfd to the address addr. ssize_t write(sockfd, void *buf, size_t, len); ssize_t read(sockfd, void *buf, size_t len); // Same but with optional flag parameters (can be 0 in simple cases) ssize_t send(int sockfs, const void *buf, size_t len, int flags); ssize_t recv(int sockfd, void *buf, size_t len, int flags); ","date":"01-01-0001","objectID":"/socket_programming/:0:0","tags":["C","Systems Programming","Networking","Sockets"],"title":"Socket Programming (TCP)","uri":"/socket_programming/"},{"categories":["Tutorial"],"content":"Strace is a command used to view the system calls made by an executable program during runtime, it is especially helpful when trying to debug a systems program. Basic strace commands: strace \u003cprogram executable\u003e # output to stdout the full output strace -o \u003cfile.out\u003e \u003cprogex\u003e # output to \u003cfile.out\u003e instead of stdout strace -e \u003ccommand\u003e \u003cprogex\u003e # only output specific \u003ccommand\u003e (i.e openat/read etc) strace -e trace=\u003ccommand1, command2, ...\u003e \u003cprogex\u003e sudo strace -p \u003cpid\u003e -o \u003cfile.out\u003e # Can track running process (use tail -f \u003cfile\u003e to track updates) sudo strace -p $(pgrep \u003cprog\u003e) -o \u003cfile.out\u003e;tail -f \u003cfile.out\u003e # as example flags: -t : Give timestamp to each call printed from strace -r : Same but with relative time (to first sys call) -c : Output statistics about sys calls (gives totals, time spent calling each etc) ","date":"01-01-0001","objectID":"/strace/:0:0","tags":["Linux","Command Line Tools"],"title":"strace","uri":"/strace/"},{"categories":["Tutorial"],"content":"Source strace examples ","date":"01-01-0001","objectID":"/strace/:0:1","tags":["Linux","Command Line Tools"],"title":"strace","uri":"/strace/"}]